{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "900a4460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 20:35:47,775\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "import copy\n",
    "import ray\n",
    "import warnings\n",
    "\n",
    "\n",
    "out_dir=\"./log/\"\n",
    "ray.init()\n",
    "\n",
    "\n",
    "def replace_str(target):\n",
    "    target = target.replace('\\n', '')\n",
    "    target = target.replace(',', '')\n",
    "    return target\n",
    "\n",
    "def find_value(arr, target, jumpto=1):\n",
    "    try:\n",
    "        num = replace_str(arr[arr.index(target)+jumpto])\n",
    "    except:\n",
    "        raise ValueError(\n",
    "            f'{arr}, {target}')\n",
    "    return num\n",
    "\n",
    "with open('./sim_conf.json') as json_file:\n",
    "    conf = json.load(json_file)\n",
    "\n",
    "\n",
    "conf_share=ray.put(conf)\n",
    "# TODO: fix directory finding as input\n",
    "# origin_filename = \"fsNprepNloadNtrain_Imagenet_default_resnet50_epoch5_b2048_worker12_thread0\"\n",
    "# origin_filename = \"fsNprepNloadNtrain_Imagenet_randaugment_resnet50_epoch5_b2048_worker12_thread0\"\n",
    "\n",
    "origin_filename = conf[\"FILE\"]\n",
    "# origin_filename = \"fsNprepNloadNtrain_openimage_default_resnet50_epoch1_b2048_worker12_thread0\"\n",
    "\n",
    "simp_filename = f'{origin_filename}_simp'\n",
    "fetch_filename = f\"{simp_filename}_fetchdifftime\"\n",
    "startdiff_filename = f\"{simp_filename}_fetchstartdifftime\"\n",
    "parse_dir = \"../dsanalyzer_parsed/DDP4GPUFULLTRACE/{suffix}/{filename}.csv\"\n",
    "\n",
    "perf_datafile = parse_dir.format(suffix=\"\", filename= origin_filename)\n",
    "\n",
    "simp_datafile = parse_dir.format(suffix=\"simp\", filename= simp_filename)\n",
    "fetch_datafile = parse_dir.format(suffix=\"simp\", filename= fetch_filename)\n",
    "startdiff_datafile = parse_dir.format(suffix=\"simp\", filename= startdiff_filename)\n",
    "\n",
    "perf_df = pd.read_csv(perf_datafile, index_col=0)\n",
    "perf_df = perf_df[perf_df[\"Epoch\"] == 1].sort_values(by=[\"Epoch\", \"Step\"])\n",
    "simp_df = pd.read_csv(simp_datafile, index_col=0)\n",
    "fetch_df = pd.read_csv(fetch_datafile, index_col=0)\n",
    "start_df = pd.read_csv(startdiff_datafile, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e52c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train type and setup\n",
    "info = perf_datafile.split('/')\n",
    "\n",
    "trainType = find_value(info, \"dsanalyzer_parsed\")\n",
    "\n",
    "if trainType.find(\"2GPU\") != -1: \n",
    "    gpu_num = 2\n",
    "if trainType.find(\"4GPU\") != -1:\n",
    "    gpu_num = 4\n",
    "elif trainType.find(\"DDP\") != -1:\n",
    "    gpu_num = 8\n",
    "else:\n",
    "    gpu_num = 1\n",
    "    \n",
    "trainType_share = ray.put(trainType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd21183",
   "metadata": {},
   "source": [
    "# Fetch time align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010d43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make gpu columns for simulation\n",
    "gpu_start_col = []\n",
    "gpu_fetch_col = []\n",
    "gpu_fetch_done_col = []\n",
    "gpu_training_stall_col = []\n",
    "gpu_training_col = []\n",
    "gpu_training_time_col = []\n",
    "gpu_pure_training_col = []\n",
    "\n",
    "single_gpu_prefetch_count = []\n",
    "train_col= [\"Epoch\", \"Index number\"]\n",
    "\n",
    "for i in range(gpu_num):\n",
    "    gpu_start_col.append(f\"Start time_gpu{i}\")\n",
    "    gpu_fetch_col.append(f\"Fetch time (sec)_gpu{i}\")\n",
    "    gpu_fetch_done_col.append(f\"Fetch done time (sec)_gpu{i}\")\n",
    "    gpu_training_stall_col.append(f\"Training Stall time (sec)_gpu{i}\")\n",
    "    gpu_training_col.append(f\"Training start time_gpu{i}\")\n",
    "    gpu_training_time_col.append(f\"Iteration time (sec)_gpu{i}\")\n",
    "    gpu_pure_training_col.append(f\"Pure training_gpu{i}\")\n",
    "    start_df[gpu_start_col[i]] = pd.to_datetime(\n",
    "                                    start_df[gpu_start_col[i]], format='%Y-%m-%d %H:%M:%S.%f', errors='ignore')\n",
    "\n",
    "# Init simulation informations\n",
    "simulation_df = pd.DataFrame()\n",
    "\n",
    "simulation_df[train_col] = fetch_df[train_col]\n",
    "\n",
    "simulation_df = simulation_df.merge(right=fetch_df[train_col+gpu_fetch_col], \n",
    "                                    on = train_col)\n",
    "simulation_df = simulation_df.merge(right=start_df[train_col+gpu_start_col], \n",
    "                                    on = train_col)\n",
    "\n",
    "simulation_df[\"Min fetch time (sec)\"] = fetch_df[gpu_fetch_col].min(axis=1)\n",
    "simulation_df[\"Avg fetch time (sec)\"] = fetch_df[gpu_fetch_col].mean(axis=1)\n",
    "simulation_df[\"Min start time\"] = start_df[gpu_start_col].min(axis=1)\n",
    "\n",
    "simulation_df.sort_values(by=train_col, inplace = True)\n",
    "simulation_df.reset_index(inplace = True, drop = True)\n",
    "simulation_df = simulation_df[simulation_df[\"Epoch\"] == 1]\n",
    "\n",
    "for i in range(gpu_num):\n",
    "    simulation_df[gpu_fetch_done_col[i]] = simulation_df[gpu_start_col[i]] + pd.to_timedelta(simulation_df[gpu_fetch_col[i]], 's')\n",
    "    simulation_df[gpu_training_col[i]] = pd.to_datetime(\n",
    "                                    perf_df[perf_df[\"GPU\"] == i][\"Time\"].reset_index(drop=True), format='%Y-%m-%d %H:%M:%S.%f', errors='ignore')\n",
    "    simulation_df[gpu_training_time_col[i]] = perf_df[perf_df[\"GPU\"] == i][\"Iteration time (sec)\"].reset_index(drop=True)\n",
    "    simulation_df[gpu_training_stall_col[i]] = perf_df[perf_df[\"GPU\"] == i][\"Training stall time (sec)\"].reset_index(drop=True)\n",
    "max_index_number = simulation_df[\"Index number\"].max()\n",
    "max_index_number_share = ray.put(max_index_number)\n",
    "\n",
    "simulation_df_share = ray.put(simulation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc65518d-80f0-4aed-8ec3-ad086ab869e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Index number</th>\n",
       "      <th>Fetch time (sec)_gpu0</th>\n",
       "      <th>Fetch time (sec)_gpu1</th>\n",
       "      <th>Fetch time (sec)_gpu2</th>\n",
       "      <th>Fetch time (sec)_gpu3</th>\n",
       "      <th>Start time_gpu0</th>\n",
       "      <th>Start time_gpu1</th>\n",
       "      <th>Start time_gpu2</th>\n",
       "      <th>Start time_gpu3</th>\n",
       "      <th>...</th>\n",
       "      <th>Iteration time (sec)_gpu1</th>\n",
       "      <th>Training Stall time (sec)_gpu1</th>\n",
       "      <th>Fetch done time (sec)_gpu2</th>\n",
       "      <th>Training start time_gpu2</th>\n",
       "      <th>Iteration time (sec)_gpu2</th>\n",
       "      <th>Training Stall time (sec)_gpu2</th>\n",
       "      <th>Fetch done time (sec)_gpu3</th>\n",
       "      <th>Training start time_gpu3</th>\n",
       "      <th>Iteration time (sec)_gpu3</th>\n",
       "      <th>Training Stall time (sec)_gpu3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.112918</td>\n",
       "      <td>8.386826</td>\n",
       "      <td>8.087636</td>\n",
       "      <td>8.168932</td>\n",
       "      <td>2021-09-01 19:48:46.728082</td>\n",
       "      <td>2021-09-01 19:48:46.722174</td>\n",
       "      <td>2021-09-01 19:48:46.727364</td>\n",
       "      <td>2021-09-01 19:48:46.727068</td>\n",
       "      <td>...</td>\n",
       "      <td>9.777527</td>\n",
       "      <td>8.904674</td>\n",
       "      <td>2021-09-01 19:48:54.814999759</td>\n",
       "      <td>2021-09-01 19:48:55.268586</td>\n",
       "      <td>9.778004</td>\n",
       "      <td>8.673933</td>\n",
       "      <td>2021-09-01 19:48:54.895999750</td>\n",
       "      <td>2021-09-01 19:48:55.280864</td>\n",
       "      <td>9.777059</td>\n",
       "      <td>8.685712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.426491</td>\n",
       "      <td>8.199841</td>\n",
       "      <td>8.215275</td>\n",
       "      <td>8.266806</td>\n",
       "      <td>2021-09-01 19:48:46.727509</td>\n",
       "      <td>2021-09-01 19:48:46.722159</td>\n",
       "      <td>2021-09-01 19:48:46.727725</td>\n",
       "      <td>2021-09-01 19:48:46.727194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895753</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2021-09-01 19:48:54.942999923</td>\n",
       "      <td>2021-09-01 19:48:56.095136</td>\n",
       "      <td>0.894281</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2021-09-01 19:48:54.994000042</td>\n",
       "      <td>2021-09-01 19:48:56.093251</td>\n",
       "      <td>0.895666</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.220429</td>\n",
       "      <td>8.060581</td>\n",
       "      <td>11.568502</td>\n",
       "      <td>8.332884</td>\n",
       "      <td>2021-09-01 19:48:46.727571</td>\n",
       "      <td>2021-09-01 19:48:46.722419</td>\n",
       "      <td>2021-09-01 19:48:46.727498</td>\n",
       "      <td>2021-09-01 19:48:46.727116</td>\n",
       "      <td>...</td>\n",
       "      <td>2.217993</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2021-09-01 19:48:58.295999747</td>\n",
       "      <td>2021-09-01 19:48:58.612528</td>\n",
       "      <td>2.219373</td>\n",
       "      <td>1.345563</td>\n",
       "      <td>2021-09-01 19:48:55.060000074</td>\n",
       "      <td>2021-09-01 19:48:56.990001</td>\n",
       "      <td>2.218280</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.567206</td>\n",
       "      <td>8.384353</td>\n",
       "      <td>8.628927</td>\n",
       "      <td>8.750336</td>\n",
       "      <td>2021-09-01 19:48:55.044794</td>\n",
       "      <td>2021-09-01 19:48:55.326647</td>\n",
       "      <td>2021-09-01 19:48:55.015073</td>\n",
       "      <td>2021-09-01 19:48:55.105664</td>\n",
       "      <td>...</td>\n",
       "      <td>5.680156</td>\n",
       "      <td>4.572775</td>\n",
       "      <td>2021-09-01 19:49:03.643999721</td>\n",
       "      <td>2021-09-01 19:49:03.968382</td>\n",
       "      <td>5.680703</td>\n",
       "      <td>4.482008</td>\n",
       "      <td>2021-09-01 19:49:03.855999751</td>\n",
       "      <td>2021-09-01 19:49:04.292639</td>\n",
       "      <td>5.680231</td>\n",
       "      <td>4.805935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8.976840</td>\n",
       "      <td>9.103020</td>\n",
       "      <td>8.669292</td>\n",
       "      <td>8.500594</td>\n",
       "      <td>2021-09-01 19:48:55.374160</td>\n",
       "      <td>2021-09-01 19:48:55.129980</td>\n",
       "      <td>2021-09-01 19:48:55.147708</td>\n",
       "      <td>2021-09-01 19:48:55.201406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894344</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2021-09-01 19:49:03.817000187</td>\n",
       "      <td>2021-09-01 19:49:04.660043</td>\n",
       "      <td>0.893107</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2021-09-01 19:49:03.702000102</td>\n",
       "      <td>2021-09-01 19:49:04.890191</td>\n",
       "      <td>0.894026</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>1</td>\n",
       "      <td>846</td>\n",
       "      <td>8.700867</td>\n",
       "      <td>8.742307</td>\n",
       "      <td>8.309392</td>\n",
       "      <td>8.876083</td>\n",
       "      <td>2021-09-01 20:32:38.071133</td>\n",
       "      <td>2021-09-01 20:32:35.288693</td>\n",
       "      <td>2021-09-01 20:32:42.396608</td>\n",
       "      <td>2021-09-01 20:32:35.873917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895935</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2021-09-01 20:32:50.705999790</td>\n",
       "      <td>2021-09-01 20:32:52.856106</td>\n",
       "      <td>0.895963</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2021-09-01 20:32:44.749999610</td>\n",
       "      <td>2021-09-01 20:32:52.857808</td>\n",
       "      <td>0.895931</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>1</td>\n",
       "      <td>847</td>\n",
       "      <td>8.788954</td>\n",
       "      <td>8.310897</td>\n",
       "      <td>8.926671</td>\n",
       "      <td>8.654566</td>\n",
       "      <td>2021-09-01 20:32:36.299046</td>\n",
       "      <td>2021-09-01 20:32:42.242103</td>\n",
       "      <td>2021-09-01 20:32:36.710329</td>\n",
       "      <td>2021-09-01 20:32:36.001434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897361</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2021-09-01 20:32:45.636999536</td>\n",
       "      <td>2021-09-01 20:32:53.752485</td>\n",
       "      <td>0.898650</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2021-09-01 20:32:44.655999743</td>\n",
       "      <td>2021-09-01 20:32:53.753998</td>\n",
       "      <td>0.898609</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>1</td>\n",
       "      <td>848</td>\n",
       "      <td>8.836856</td>\n",
       "      <td>7.349450</td>\n",
       "      <td>8.761064</td>\n",
       "      <td>8.692516</td>\n",
       "      <td>2021-09-01 20:32:39.316144</td>\n",
       "      <td>2021-09-01 20:32:52.088550</td>\n",
       "      <td>2021-09-01 20:32:37.389936</td>\n",
       "      <td>2021-09-01 20:32:36.898484</td>\n",
       "      <td>...</td>\n",
       "      <td>5.699361</td>\n",
       "      <td>4.828246</td>\n",
       "      <td>2021-09-01 20:32:46.151000104</td>\n",
       "      <td>2021-09-01 20:32:54.656551</td>\n",
       "      <td>5.698582</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2021-09-01 20:32:45.590999536</td>\n",
       "      <td>2021-09-01 20:32:54.650665</td>\n",
       "      <td>5.698188</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>1</td>\n",
       "      <td>849</td>\n",
       "      <td>8.056848</td>\n",
       "      <td>8.511557</td>\n",
       "      <td>7.986414</td>\n",
       "      <td>8.299552</td>\n",
       "      <td>2021-09-01 20:32:46.992152</td>\n",
       "      <td>2021-09-01 20:32:44.249443</td>\n",
       "      <td>2021-09-01 20:32:50.900586</td>\n",
       "      <td>2021-09-01 20:32:44.983448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895900</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2021-09-01 20:32:58.886999697</td>\n",
       "      <td>2021-09-01 20:33:00.350174</td>\n",
       "      <td>0.895987</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2021-09-01 20:32:53.283000161</td>\n",
       "      <td>2021-09-01 20:33:00.348954</td>\n",
       "      <td>0.895796</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>8.529654</td>\n",
       "      <td>7.894888</td>\n",
       "      <td>8.534529</td>\n",
       "      <td>9.017146</td>\n",
       "      <td>2021-09-01 20:32:45.332346</td>\n",
       "      <td>2021-09-01 20:32:50.756112</td>\n",
       "      <td>2021-09-01 20:32:45.877471</td>\n",
       "      <td>2021-09-01 20:32:45.124854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894848</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2021-09-01 20:32:54.411999722</td>\n",
       "      <td>2021-09-01 20:33:01.245824</td>\n",
       "      <td>0.894405</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2021-09-01 20:32:54.141999959</td>\n",
       "      <td>2021-09-01 20:33:01.245870</td>\n",
       "      <td>0.894802</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>851 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Epoch  Index number  Fetch time (sec)_gpu0  Fetch time (sec)_gpu1  \\\n",
       "0        1             0               8.112918               8.386826   \n",
       "1        1             1               8.426491               8.199841   \n",
       "2        1             2               8.220429               8.060581   \n",
       "3        1             3               8.567206               8.384353   \n",
       "4        1             4               8.976840               9.103020   \n",
       "..     ...           ...                    ...                    ...   \n",
       "846      1           846               8.700867               8.742307   \n",
       "847      1           847               8.788954               8.310897   \n",
       "848      1           848               8.836856               7.349450   \n",
       "849      1           849               8.056848               8.511557   \n",
       "850      1           850               8.529654               7.894888   \n",
       "\n",
       "     Fetch time (sec)_gpu2  Fetch time (sec)_gpu3            Start time_gpu0  \\\n",
       "0                 8.087636               8.168932 2021-09-01 19:48:46.728082   \n",
       "1                 8.215275               8.266806 2021-09-01 19:48:46.727509   \n",
       "2                11.568502               8.332884 2021-09-01 19:48:46.727571   \n",
       "3                 8.628927               8.750336 2021-09-01 19:48:55.044794   \n",
       "4                 8.669292               8.500594 2021-09-01 19:48:55.374160   \n",
       "..                     ...                    ...                        ...   \n",
       "846               8.309392               8.876083 2021-09-01 20:32:38.071133   \n",
       "847               8.926671               8.654566 2021-09-01 20:32:36.299046   \n",
       "848               8.761064               8.692516 2021-09-01 20:32:39.316144   \n",
       "849               7.986414               8.299552 2021-09-01 20:32:46.992152   \n",
       "850               8.534529               9.017146 2021-09-01 20:32:45.332346   \n",
       "\n",
       "               Start time_gpu1            Start time_gpu2  \\\n",
       "0   2021-09-01 19:48:46.722174 2021-09-01 19:48:46.727364   \n",
       "1   2021-09-01 19:48:46.722159 2021-09-01 19:48:46.727725   \n",
       "2   2021-09-01 19:48:46.722419 2021-09-01 19:48:46.727498   \n",
       "3   2021-09-01 19:48:55.326647 2021-09-01 19:48:55.015073   \n",
       "4   2021-09-01 19:48:55.129980 2021-09-01 19:48:55.147708   \n",
       "..                         ...                        ...   \n",
       "846 2021-09-01 20:32:35.288693 2021-09-01 20:32:42.396608   \n",
       "847 2021-09-01 20:32:42.242103 2021-09-01 20:32:36.710329   \n",
       "848 2021-09-01 20:32:52.088550 2021-09-01 20:32:37.389936   \n",
       "849 2021-09-01 20:32:44.249443 2021-09-01 20:32:50.900586   \n",
       "850 2021-09-01 20:32:50.756112 2021-09-01 20:32:45.877471   \n",
       "\n",
       "               Start time_gpu3  ...  Iteration time (sec)_gpu1  \\\n",
       "0   2021-09-01 19:48:46.727068  ...                   9.777527   \n",
       "1   2021-09-01 19:48:46.727194  ...                   0.895753   \n",
       "2   2021-09-01 19:48:46.727116  ...                   2.217993   \n",
       "3   2021-09-01 19:48:55.105664  ...                   5.680156   \n",
       "4   2021-09-01 19:48:55.201406  ...                   0.894344   \n",
       "..                         ...  ...                        ...   \n",
       "846 2021-09-01 20:32:35.873917  ...                   0.895935   \n",
       "847 2021-09-01 20:32:36.001434  ...                   0.897361   \n",
       "848 2021-09-01 20:32:36.898484  ...                   5.699361   \n",
       "849 2021-09-01 20:32:44.983448  ...                   0.895900   \n",
       "850 2021-09-01 20:32:45.124854  ...                   0.894848   \n",
       "\n",
       "     Training Stall time (sec)_gpu1    Fetch done time (sec)_gpu2  \\\n",
       "0                          8.904674 2021-09-01 19:48:54.814999759   \n",
       "1                          0.000002 2021-09-01 19:48:54.942999923   \n",
       "2                          0.000002 2021-09-01 19:48:58.295999747   \n",
       "3                          4.572775 2021-09-01 19:49:03.643999721   \n",
       "4                          0.000002 2021-09-01 19:49:03.817000187   \n",
       "..                              ...                           ...   \n",
       "846                        0.000003 2021-09-01 20:32:50.705999790   \n",
       "847                        0.000002 2021-09-01 20:32:45.636999536   \n",
       "848                        4.828246 2021-09-01 20:32:46.151000104   \n",
       "849                        0.000002 2021-09-01 20:32:58.886999697   \n",
       "850                        0.000003 2021-09-01 20:32:54.411999722   \n",
       "\n",
       "      Training start time_gpu2 Iteration time (sec)_gpu2  \\\n",
       "0   2021-09-01 19:48:55.268586                  9.778004   \n",
       "1   2021-09-01 19:48:56.095136                  0.894281   \n",
       "2   2021-09-01 19:48:58.612528                  2.219373   \n",
       "3   2021-09-01 19:49:03.968382                  5.680703   \n",
       "4   2021-09-01 19:49:04.660043                  0.893107   \n",
       "..                         ...                       ...   \n",
       "846 2021-09-01 20:32:52.856106                  0.895963   \n",
       "847 2021-09-01 20:32:53.752485                  0.898650   \n",
       "848 2021-09-01 20:32:54.656551                  5.698582   \n",
       "849 2021-09-01 20:33:00.350174                  0.895987   \n",
       "850 2021-09-01 20:33:01.245824                  0.894405   \n",
       "\n",
       "     Training Stall time (sec)_gpu2    Fetch done time (sec)_gpu3  \\\n",
       "0                          8.673933 2021-09-01 19:48:54.895999750   \n",
       "1                          0.000006 2021-09-01 19:48:54.994000042   \n",
       "2                          1.345563 2021-09-01 19:48:55.060000074   \n",
       "3                          4.482008 2021-09-01 19:49:03.855999751   \n",
       "4                          0.000006 2021-09-01 19:49:03.702000102   \n",
       "..                              ...                           ...   \n",
       "846                        0.000006 2021-09-01 20:32:44.749999610   \n",
       "847                        0.000006 2021-09-01 20:32:44.655999743   \n",
       "848                        0.000006 2021-09-01 20:32:45.590999536   \n",
       "849                        0.000006 2021-09-01 20:32:53.283000161   \n",
       "850                        0.000006 2021-09-01 20:32:54.141999959   \n",
       "\n",
       "      Training start time_gpu3 Iteration time (sec)_gpu3  \\\n",
       "0   2021-09-01 19:48:55.280864                  9.777059   \n",
       "1   2021-09-01 19:48:56.093251                  0.895666   \n",
       "2   2021-09-01 19:48:56.990001                  2.218280   \n",
       "3   2021-09-01 19:49:04.292639                  5.680231   \n",
       "4   2021-09-01 19:49:04.890191                  0.894026   \n",
       "..                         ...                       ...   \n",
       "846 2021-09-01 20:32:52.857808                  0.895931   \n",
       "847 2021-09-01 20:32:53.753998                  0.898609   \n",
       "848 2021-09-01 20:32:54.650665                  5.698188   \n",
       "849 2021-09-01 20:33:00.348954                  0.895796   \n",
       "850 2021-09-01 20:33:01.245870                  0.894802   \n",
       "\n",
       "     Training Stall time (sec)_gpu3  \n",
       "0                          8.685712  \n",
       "1                          0.000002  \n",
       "2                          0.000002  \n",
       "3                          4.805935  \n",
       "4                          0.000002  \n",
       "..                              ...  \n",
       "846                        0.000003  \n",
       "847                        0.000003  \n",
       "848                        0.000002  \n",
       "849                        0.000002  \n",
       "850                        0.000002  \n",
       "\n",
       "[851 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622f3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  train_col + gpu_start_col + gpu_fetch_col + gpu_fetch_done_col\n",
    "\n",
    "# Preprocessing time align\n",
    "FETCH_ALIGNs = conf[\"FETCH_ALIGN\"]\n",
    "# Preprocessing start time align\n",
    "START_ALIGNs = conf[\"START_ALIGN\"]\n",
    "\n",
    "\n",
    "\n",
    "def simulate_dataload(FETCH_ALIGN, START_ALIGN, idx, row, sim_dataload_df, sim_train_df, conf):\n",
    "    simulated_gpu_info = {}\n",
    "    \n",
    "    for i in range(gpu_num):\n",
    "        # Simulate based on the number of workers\n",
    "\n",
    "        if START_ALIGN == \"avg\":\n",
    "            next_fetch_start_time = row[gpu_start_col].max() - ((row[gpu_start_col].max() - row[gpu_start_col].min()) / 2)\n",
    "        elif START_ALIGN == \"min\":\n",
    "            next_fetch_start_time = row[gpu_start_col].min()\n",
    "        else:\n",
    "            next_fetch_start_time = row[gpu_start_col[i]]\n",
    "\n",
    "        simulated_gpu_info[gpu_start_col[i]] = next_fetch_start_time\n",
    "#         print(next_fetch_start_time)\n",
    "\n",
    "        if FETCH_ALIGN == \"avg\":\n",
    "            fetch_time = row[\"Avg fetch time (sec)\"]\n",
    "        elif FETCH_ALIGN == \"min\":\n",
    "            fetch_time = row[\"Min fetch time (sec)\"]\n",
    "        else:\n",
    "            fetch_time = row[gpu_fetch_col[i]]\n",
    "            \n",
    "        simulated_gpu_info[gpu_fetch_col[i]] = fetch_time # + conf[\"FETCH_DELAY\"]\n",
    "                                                                                                                 \n",
    "        simulated_gpu_info[gpu_fetch_done_col[i]] = simulated_gpu_info[gpu_start_col[i]] + pd.to_timedelta(simulated_gpu_info[gpu_fetch_col[i]], 's')\n",
    "    return simulated_gpu_info\n",
    "\n",
    "def simulate_training(FETCH_ALIGN, START_ALIGN, idx, row, sim_dataload_df, sim_train_df):\n",
    "    # FIXME: Manually tune with idx\n",
    "    fetch_done_times = sim_dataload_df.loc[idx][gpu_fetch_done_col]\n",
    "    \n",
    "    slowest_fetch_time = fetch_done_times.max()\n",
    "    \n",
    "    # INFO\n",
    "    info_fetch_done_times = row[gpu_fetch_done_col]\n",
    "    info_slowest_fetch_time = info_fetch_done_times.max()\n",
    "    info_training_start_times = row[gpu_training_col].values\n",
    "    info_training_times = row[gpu_training_time_col].values\n",
    "    info_training_stall_times = row[gpu_training_stall_col].values\n",
    "    info_pure_training_times = info_training_times - info_training_stall_times.max()\n",
    "    info_training_end_times = info_training_start_times + pd.to_timedelta(info_pure_training_times, 's')\n",
    "    info_data_require_times = info_training_start_times - pd.to_timedelta(info_training_stall_times.max(), 's')\n",
    "    \n",
    "    if FETCH_ALIGN or START_ALIGN:\n",
    "        sim_gaps = np.array([])\n",
    "        training_stall_times = np.array([])\n",
    "        for _info_fetch_done_time, _fetch_done_time, _training_stall_time in zip(info_fetch_done_times.values, fetch_done_times.values, info_training_stall_times):\n",
    "            if _info_fetch_done_time > _fetch_done_time:\n",
    "                _sim_gap = _info_fetch_done_time - _fetch_done_time\n",
    "                new_training_stall_time = _training_stall_time - (_sim_gap / np.timedelta64(1, 's'))\n",
    "                if new_training_stall_time < 0.0:\n",
    "                    new_training_stall_time = 0.000002\n",
    "            elif _info_fetch_done_time < _fetch_done_time:\n",
    "                _sim_gap = _fetch_done_time - _info_fetch_done_time\n",
    "                # FIXME: Need to check it actually slowdown\n",
    "                if _training_stall_time > 0.01:\n",
    "                    new_training_stall_time = _training_stall_time + (_sim_gap / np.timedelta64(1, 's'))\n",
    "                else:\n",
    "                    new_training_stall_time = _training_stall_time\n",
    "            else:\n",
    "                _sim_gap = pd.Timedelta(0, 's')\n",
    "                new_training_stall_time = _training_stall_time\n",
    "#             print(sim_gaps, type(_sim_gap))\n",
    "            sim_gaps = np.append(sim_gaps, _sim_gap)\n",
    "            training_stall_times = np.append(training_stall_times, new_training_stall_time)\n",
    "        training_times = training_stall_times.max() + info_pure_training_times\n",
    "        training_end_times = info_training_start_times + pd.Timedelta(training_times.max())\n",
    "    else:\n",
    "        training_times = info_training_times\n",
    "        training_end_times = info_training_end_times\n",
    "        training_stall_times = info_training_stall_times\n",
    "        \n",
    "    done_row = {\"Slowest end time\":slowest_fetch_time, \"Training end time\":training_end_times.max(), \"Training time\": training_times.max()}\n",
    "\n",
    "    for i in range(gpu_num):\n",
    "        done_row[gpu_training_col[i]] = info_training_start_times[i]\n",
    "        done_row[gpu_pure_training_col[i]] = info_pure_training_times[i]\n",
    "        done_row[gpu_training_stall_col[i]] = training_stall_times[i]\n",
    "        \n",
    "    delay_time = training_stall_times.max() - training_stall_times.min()\n",
    "    done_row[\"Delay time (sec)\"] = delay_time\n",
    "    done_row[\"Training stall time (sec)\"] = training_stall_times.max()\n",
    "    \n",
    "    return done_row\n",
    "\n",
    "@ray.remote\n",
    "def simulation(FETCH_ALIGN,START_ALIGN, conf, trainType, simulation_df, max_index_number):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    simulated_df = pd.DataFrame(columns=columns)\n",
    "    done_df = pd.DataFrame(columns=[\"Slowest end time\", \"Training time\",\"Training end time\", \"Delay time (sec)\",\"Training stall time (sec)\"]+gpu_training_col+gpu_pure_training_col+gpu_training_stall_col)\n",
    "    \n",
    "    for idx, row in simulation_df.iterrows():\n",
    "        simulated_row = {}\n",
    "        simulated_row[train_col[0]] = row[train_col[0]]\n",
    "        simulated_row[train_col[1]] = row[train_col[1]]\n",
    "        \n",
    "        simulated_row.update(simulate_dataload(FETCH_ALIGN, START_ALIGN, idx, row, simulated_df, done_df, conf))\n",
    "\n",
    "        simulated_df.loc[len(simulated_df)] = simulated_row\n",
    "#         print(done_row)\n",
    "        done_df.loc[len(simulated_df)] = simulate_training(FETCH_ALIGN, START_ALIGN, idx, row, simulated_df, done_df)\n",
    "#     print(done_df)   \n",
    "    sim_train_df = pd.DataFrame()\n",
    "    sim_train_df[train_col] = simulation_df[train_col].reset_index(drop=True)\n",
    "    sim_train_df[\"Iteration time (sec)\"] = done_df[\"Training time\"].reset_index(drop=True)\n",
    "    sim_train_df[gpu_training_stall_col] = done_df[gpu_training_stall_col].reset_index(drop=True)\n",
    "    sim_train_df[\"Training stall time (sec)\"] = done_df[\"Training stall time (sec)\"].reset_index(drop=True)\n",
    "    sim_train_df[\"Delay time (sec)\"] = done_df[\"Delay time (sec)\"].reset_index(drop=True)\n",
    "    sim_train_df[\"Batch fetch time diff (sec)\"]  = simulated_df[gpu_fetch_col].max(axis=1) - simulated_df[gpu_fetch_col].min(axis=1)\n",
    "    sim_train_df[\"Batch fetch start time diff (sec)\"] = (simulated_df[gpu_start_col].max(axis=1) - simulated_df[gpu_start_col].min(axis=1)).dt.total_seconds()\n",
    "    \n",
    "    os.makedirs(f\"./no_deps/{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/debug\", exist_ok=True)\n",
    "    \n",
    "    sim_train_df.to_csv(f\"./no_deps/{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/{origin_filename}.csv\")\n",
    "    \n",
    "    simulated_df.to_csv(f\"./no_deps/{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/debug/dataload_sim.csv\")\n",
    "    done_df.to_csv(f\"./no_deps/{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/debug/train_sim.csv\")\n",
    "    simulation_df.to_csv(f\"./no_deps/{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/debug/sim_info.csv\")\n",
    "    return simulated_df\n",
    "\n",
    "# Initialization\n",
    "conf_combinations = list(itertools.product(FETCH_ALIGNs, START_ALIGNs))\n",
    "result_ids = []\n",
    "for FETCH_ALIGN, START_ALIGN in conf_combinations:\n",
    "    result_ids.append(simulation.remote(FETCH_ALIGN,START_ALIGN, conf_share, \n",
    "                                        trainType_share, simulation_df_share, max_index_number_share))\n",
    "    #     # Debug break\n",
    "#     break\n",
    "    \n",
    "while len(result_ids):\n",
    "    done_id, result_ids = ray.wait(result_ids)\n",
    "    ray.get(done_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8530978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 20:59:44,153\tERROR worker.py:468 -- print_logs: Connection closed by server.\n",
      "2021-09-01 20:59:44,154\tERROR worker.py:1191 -- listen_error_messages_raylet: Connection closed by server.\n",
      "2021-09-01 20:59:44,154\tERROR import_thread.py:88 -- ImportThread: Connection closed by server.\n"
     ]
    }
   ],
   "source": [
    "dir_names = glob.glob(\n",
    "               f\"./no_deps/{trainType}/*/*.csv\")\n",
    "\n",
    "dataset_col_name = [\"Align\",\"Log type\", \"Dataset size(GB)\", \"Model\", \"Augmentation\", \"Worker\", \"Worker batch size\", \"Epoch\", \"Batch size\", \"Avg iteration time (sec)\",\n",
    "                               \"Avg training stall time (sec)\", \"Avg delay time (sec)\", \"Effective Delay time (%)\", \"Avg preprocessing start diff (sec)\", \"Avg preprocessing diff (sec)\"]\n",
    "total_log = [] \n",
    "\n",
    "for logdir in dir_names:\n",
    "    split_logdir = logdir.split('/')\n",
    "    align_type = split_logdir[-2]\n",
    "    parse_filename = split_logdir[-1]\n",
    "    logdir_list = parse_filename.split(\"_\")\n",
    "#         print(logdir_list)\n",
    "    logtype = logdir_list[0]\n",
    "    dataset = logdir_list[1]\n",
    "    aug = find_value(logdir_list, dataset)\n",
    "    model = find_value(logdir_list, aug)\n",
    "    epoch = find_value(logdir_list, model)\n",
    "    batchsize = find_value(logdir_list, epoch)\n",
    "    worker = find_value(logdir_list, batchsize)\n",
    "    thread = find_value(logdir_list, worker).replace(\".csv\",\"\")\n",
    "    model = model.replace(\"_\", \"\")\n",
    "\n",
    "    epoch_num = int(epoch.replace(\"epoch\", \"\"))\n",
    "    batchsize_num = int(batchsize.replace(\"b\", \"\"))\n",
    "    single_batchsize_num = batchsize_num/gpu_num\n",
    "    conf[\"WORKER_NUM\"] = int(worker.replace(\"worker\", \"\"))\n",
    "    thread_num = int(thread.replace(\"thread\", \"\"))\n",
    "    \n",
    "    df = pd.read_csv(logdir, index_col=None)\n",
    "    df = df[df[\"Index number\"]>10]\n",
    "#     gpu_log = []\n",
    "\n",
    "#     for i in range(gpu_num):\n",
    "#         gpu_df = df[df[\"GPU\"] == i].dropna()\n",
    "#         gpu_epoch_time = f'{round(gpu_df[\"Iteration time (sec)\"].mean(),4)}±{round(gpu_df[\"Iteration time (sec)\"].std(),4)}'\n",
    "#         gpu_log.append(gpu_epoch_time)\n",
    "#         gpu_stall_time = f'{round(gpu_df[\"Training stall time (sec)\"].mean(),4)}±{round(gpu_df[\"Training stall time (sec)\"].std(),4)}'\n",
    "#         gpu_log.append(gpu_stall_time)\n",
    "\n",
    "\n",
    "#     df = df[df[\"Step\"] > 10]\n",
    "#     filtered_avg_epoch_time = round(\n",
    "#         df[\"Iteration time (sec)\"].astype(float).sum()/(int(epoch_num)-1), 2)\n",
    "#     print(df.describe())\n",
    "#     print(\"\\n\")\n",
    "    # print(parse_filename, df[\"Iteration time (sec)\"])\n",
    "    iter_origin = df[\"Iteration time (sec)\"].mean()\n",
    "    iter_avg = f'{round(iter_origin,4)}±{round(df[\"Iteration time (sec)\"].std(),4)}'\n",
    "    data_avg = f'{round(df[\"Training stall time (sec)\"].mean(),4)}±{round(df[\"Training stall time (sec)\"].std(),4)}'\n",
    "    delay_avg = f'{round(df[\"Delay time (sec)\"].mean(),4)}±{round(df[\"Delay time (sec)\"].std(),4)}'\n",
    "    fetch_avg = f'{round(df[\"Batch fetch time diff (sec)\"].mean(),4)}±{round(df[\"Batch fetch time diff (sec)\"].std(),4)}'\n",
    "    fetch_start_avg = f'{round(df[\"Batch fetch start time diff (sec)\"].mean(),4)}±{round(df[\"Batch fetch start time diff (sec)\"].std(),4)}'\n",
    "    \n",
    "    # NOTE: fixed effective delay time (0.030)\n",
    "    effective_delay_percent = float(len(df[df[\"Delay time (sec)\"] > 0.030])) / float(len(df)) * 100.0\n",
    "#     throughput_origin = single_batchsize_num/iter_origin\n",
    "#     throughput_avg = round(throughput_origin, 4)\n",
    "    # # [Note] :\n",
    "    # # Deprecated throughput avg,\n",
    "    # # theoretically wrong in mathematic, Please check below link\n",
    "    # # https://fxloader.com/inverse_of_an_average_compared_to_averages_of_inverses/\n",
    "    # throughput_avg = f'{round(df[\"Throughput (image/sec)\"].mean(),2)}±{round(df[\"Throughput (image/sec)\"].std(),4)}'\n",
    "\n",
    "    # FIXME: Hard coded as imagenet avg size (MB)\n",
    "#     processed_data_avg = throughput_origin * 105.53 / 1024\n",
    "\n",
    "    total_loglet = [align_type, logtype, dataset, model, aug, conf[\"WORKER_NUM\"], thread_num, epoch_num, batchsize_num,\n",
    "                    iter_avg, data_avg, delay_avg, effective_delay_percent, fetch_start_avg, fetch_avg]\n",
    "#     total_loglet.extend(gpu_log)\n",
    "    total_log.append(total_loglet)\n",
    "\n",
    "avg_df = pd.DataFrame(total_log,\n",
    "                      columns=dataset_col_name)\n",
    "avg_df.dropna().to_csv(f\"./no_deps/{trainType}/total_summary.csv\",\n",
    "                       sep=',', na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74deda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3ce3fbceb464fba96ea10ab322696e4925ec5599a979a26c56d90ff07e466ab"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
