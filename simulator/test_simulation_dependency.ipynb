{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5967c41-5fd7-4146-8586-1ef08d37fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-27 13:36:03,375\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "import glob\n",
    "import copy\n",
    "import ray\n",
    "\n",
    "\n",
    "out_dir=\"./log/\"\n",
    "ray.init()\n",
    "\n",
    "def replace_str(target):\n",
    "    target = target.replace('\\n', '')\n",
    "    target = target.replace(',', '')\n",
    "    return target\n",
    "\n",
    "def find_value(arr, target, jumpto=1):\n",
    "    try:\n",
    "        num = replace_str(arr[arr.index(target)+jumpto])\n",
    "    except:\n",
    "        raise ValueError(\n",
    "            f'{arr}, {target}')\n",
    "    return num\n",
    "\n",
    "with open('./sim_conf.json') as json_file:\n",
    "    conf = json.load(json_file)\n",
    "\n",
    "\n",
    "conf_share=ray.put(conf)\n",
    "# TODO: fix directory finding as input\n",
    "# origin_filename = \"fsNprepNloadNtrain_Imagenet_default_resnet50_epoch5_b2048_worker12_thread0\"\n",
    "# origin_filename = \"fsNprepNloadNtrain_Imagenet_randaugment_resnet50_epoch5_b2048_worker12_thread0\"\n",
    "\n",
    "origin_filename = conf[\"FILE\"]\n",
    "# origin_filename = \"fsNprepNloadNtrain_openimage_default_resnet50_epoch1_b2048_worker12_thread0\"\n",
    "\n",
    "simp_filename = f'{origin_filename}_simp'\n",
    "fetch_filename = f\"{simp_filename}_fetchdifftime\"\n",
    "startdiff_filename = f\"{simp_filename}_fetchstartdifftime\"\n",
    "parse_dir = \"../dsanalyzer_parsed/DDP4GPUFULLTRACE/{suffix}/{filename}.csv\"\n",
    "\n",
    "perf_datafile = parse_dir.format(suffix=\"\", filename= origin_filename)\n",
    "\n",
    "simp_datafile = parse_dir.format(suffix=\"simp\", filename= simp_filename)\n",
    "fetch_datafile = parse_dir.format(suffix=\"simp\", filename= fetch_filename)\n",
    "startdiff_datafile = parse_dir.format(suffix=\"simp\", filename= startdiff_filename)\n",
    "\n",
    "perf_df= pd.read_csv(perf_datafile, index_col=0)\n",
    "simp_df = pd.read_csv(simp_datafile, index_col=0)\n",
    "fetch_df = pd.read_csv(fetch_datafile, index_col=0)\n",
    "start_df = pd.read_csv(startdiff_datafile, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8eb50c4-8b6b-4f3b-bf6d-b6f54506e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train type and setup\n",
    "info = perf_datafile.split('/')\n",
    "\n",
    "trainType = find_value(info, \"dsanalyzer_parsed\")\n",
    "\n",
    "if trainType.find(\"2GPU\") != -1: \n",
    "    gpu_num = 2\n",
    "if trainType.find(\"4GPU\") != -1:\n",
    "    gpu_num = 4\n",
    "elif trainType.find(\"DDP\") != -1:\n",
    "    gpu_num = 8\n",
    "else:\n",
    "    gpu_num = 1\n",
    "    \n",
    "trainType_share = ray.put(trainType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce0cf1-d6fb-4c88-920c-c945787a6f7b",
   "metadata": {},
   "source": [
    "# Fetch time align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c3b1eb-7161-4c05-9389-fa357a2e5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make gpu columns for simulation\n",
    "gpu_start_col = []\n",
    "gpu_fetch_col = []\n",
    "gpu_fetch_done_col = []\n",
    "gpu_training_stall_col = []\n",
    "\n",
    "single_gpu_prefetch_count = []\n",
    "train_col= [\"Epoch\", \"Index number\"]\n",
    "\n",
    "for i in range(gpu_num):\n",
    "    gpu_start_col.append(f\"Start time_gpu{i}\")\n",
    "    gpu_fetch_col.append(f\"Fetch time (sec)_gpu{i}\")\n",
    "    gpu_fetch_done_col.append(f\"Fetch done time (sec)_gpu{i}\")\n",
    "    gpu_training_stall_col.append(f\"Training Stall time (sec)_gpu{i}\")\n",
    "    \n",
    "    start_df[gpu_start_col[i]] = pd.to_datetime(\n",
    "                                    start_df[gpu_start_col[i]], format='%Y-%m-%d %H:%M:%S.%f', errors='ignore')\n",
    "\n",
    "# Init simulation informations\n",
    "simulation_df = pd.DataFrame()\n",
    "\n",
    "simulation_df[train_col] = fetch_df[train_col]\n",
    "\n",
    "simulation_df = simulation_df.merge(right=fetch_df[train_col+gpu_fetch_col], \n",
    "                                    on = train_col)\n",
    "simulation_df = simulation_df.merge(right=start_df[train_col+gpu_start_col], \n",
    "                                    on = train_col)\n",
    "\n",
    "simulation_df[\"Min fetch time (sec)\"] = fetch_df[gpu_fetch_col].min(axis=1)\n",
    "simulation_df[\"Avg fetch time (sec)\"] = fetch_df[gpu_fetch_col].mean(axis=1)\n",
    "simulation_df[\"Min start time\"] = start_df[gpu_start_col].min(axis=1)\n",
    "\n",
    "simulation_df.sort_values(by=train_col, inplace = True)\n",
    "simulation_df.reset_index(inplace = True, drop = True)\n",
    "simulation_df = simulation_df[simulation_df[\"Epoch\"] == 2]\n",
    "max_index_number = simulation_df[\"Index number\"].max()\n",
    "max_index_number_share = ray.put(max_index_number)\n",
    "\n",
    "simulation_df_share = ray.put(simulation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a1a878-cc6e-4b24-bebc-b8d1d0cd7e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(TypeError)",
     "evalue": "\u001b[36mray::simulation()\u001b[39m (pid=64126, ip=10.20.22.156)\n  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n    return function(*args, **kwargs)\n  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n    return self._get_with(key)\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n    indexer = self.slice_indexer(start, stop, step)\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n    start_slice, end_slice = self.slice_locs(start, end, step=step)\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n    end_slice = self.get_slice_bound(end, \"right\")\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n    label = self._maybe_cast_slice_bound(label, side)\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n    raise self._invalid_indexer(\"slice\", label)\nTypeError: cannot do slice indexing on Index with these indexers [nan] of type float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9b1befbba0b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mdone_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;31m#     # Debug break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;31m#     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m: \u001b[36mray::simulation()\u001b[39m (pid=64126, ip=10.20.22.156)\n  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n    return function(*args, **kwargs)\n  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n    return self._get_with(key)\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n    indexer = self.slice_indexer(start, stop, step)\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n    start_slice, end_slice = self.slice_locs(start, end, step=step)\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n    end_slice = self.get_slice_bound(end, \"right\")\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n    label = self._maybe_cast_slice_bound(label, side)\n  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n    raise self._invalid_indexer(\"slice\", label)\nTypeError: cannot do slice indexing on Index with these indexers [nan] of type float"
     ]
    }
   ],
   "source": [
    "columns =  [\"Epoch\", \"Index number\"] + gpu_start_col + gpu_fetch_col + gpu_fetch_done_col\n",
    "\n",
    "# Preprocessing time align\n",
    "FETCH_ALIGNs = conf[\"FETCH_ALIGN\"]\n",
    "# Preprocessing start time align\n",
    "START_ALIGNs = conf[\"START_ALIGN\"]\n",
    "\n",
    "\n",
    "\n",
    "def simulate_dataload(FETCH_ALIGN, START_ALIGN, idx, row, sim_dataload_df, sim_train_df):\n",
    "    simulated_gpu_info = {}\n",
    "    \n",
    "    for i in range(gpu_num):\n",
    "        # Simulate based on the number of workers\n",
    "        if idx < conf[\"WORKER_NUM\"]:\n",
    "            next_fetch_start_time = row[\"Min start time\"] if START_ALIGN else row[gpu_start_col[i]]\n",
    "        else:\n",
    "            # [NOTE]: \n",
    "            # If fetch align, align with the fastest previous fetch time \n",
    "            # regardless each previous time (can be overlapped)\n",
    "            # If not, follow the previous fetch done time\n",
    "            next_fetch_start_time = sim_dataload_df.loc[idx-conf[\"WORKER_NUM\"]][gpu_fetch_done_col].min() if START_ALIGN else sim_dataload_df.loc[idx-conf[\"WORKER_NUM\"], f\"Fetch done time (sec)_gpu{i}\"]\n",
    "            next_fetch_start_time += pd.Timedelta(conf[\"FETCH_DELAY\"], 's')\n",
    "            \n",
    "            prefetch_step = conf[\"WORKER_NUM\"]*conf[\"PREFETCH_FACTOR\"]\n",
    "            if prefetch_step <= idx:\n",
    "                prefetch_bound_time = sim_train_df.loc[idx-prefetch_step+1][\"Training end time\"]\n",
    "                \n",
    "                if next_fetch_start_time < prefetch_bound_time:\n",
    "                    next_fetch_start_time = prefetch_bound_time + pd.Timedelta(conf[\"PREFETCH_DELAY\"], 's')\n",
    "                    \n",
    "        simulated_gpu_info[gpu_start_col[i]] = next_fetch_start_time\n",
    "#         print(next_fetch_start_time)\n",
    "        if FETCH_ALIGN == \"avg\":\n",
    "            fetch_time = row[\"Avg fetch time (sec)\"]\n",
    "        elif FETCH_ALIGN == \"min\":\n",
    "            fetch_time = row[\"Min fetch time (sec)\"]\n",
    "        else:\n",
    "            fetch_time = row[gpu_fetch_col[i]]\n",
    "            \n",
    "        simulated_gpu_info[gpu_fetch_col[i]] = fetch_time\n",
    "                                                                                                                 \n",
    "        simulated_gpu_info[gpu_fetch_done_col[i]] = simulated_gpu_info[gpu_start_col[i]] + datetime.timedelta(seconds = simulated_gpu_info[gpu_fetch_col[i]])\n",
    "    return simulated_gpu_info\n",
    "\n",
    "def simulate_training(idx, sim_dataload_df, sim_train_df):\n",
    "    # FIXME: Manually tune with idx\n",
    "    slowest_fetch_time = sim_dataload_df.loc[idx][gpu_fetch_done_col].max()\n",
    "\n",
    "    if idx == 0:\n",
    "        training_end_time = slowest_fetch_time +  pd.Timedelta(conf[\"TRAINING_TIME\"], 's')\n",
    "        pre_training_end_time = training_end_time\n",
    "    else:\n",
    "        pre_training_end_time = sim_train_df.loc[idx, \"Training end time\"]\n",
    "        if pre_training_end_time > slowest_fetch_time:\n",
    "            training_end_time = pre_training_end_time + pd.Timedelta(conf[\"PADDING_TIME\"] + conf[\"TRAINING_TIME\"], 's')\n",
    "        else:\n",
    "            training_end_time = slowest_fetch_time + pd.Timedelta(conf[\"PADDING_TIME\"] + conf[\"TRAINING_TIME\"], 's')\n",
    "    \n",
    "    gpu_fetchs = sim_dataload_df.loc[idx][gpu_fetch_done_col]\n",
    "    training_stall_times = gpu_fetchs - np.array([pre_training_end_time])\n",
    "#     print(training_stall_times)\n",
    "   \n",
    "    done_row = {\"Slowest end time\":slowest_fetch_time, \"Training end time\":training_end_time }\n",
    "    training_stall_max = 0\n",
    "    training_stall_min = 9999999.0\n",
    "    for i in range(len(training_stall_times)):\n",
    "        training_stall_seconds = training_stall_times[i].total_seconds()\n",
    "#         print(training_stall_seconds)\n",
    "        if training_stall_seconds <= 0:\n",
    "            training_stall_new_val = 0\n",
    "        else:\n",
    "            training_stall_new_val = training_stall_seconds\n",
    "        \n",
    "        done_row[f\"Training Stall time (sec)_gpu{i}\"] = training_stall_new_val\n",
    "        \n",
    "        if training_stall_max < training_stall_new_val:\n",
    "            training_stall_max = training_stall_new_val\n",
    "            \n",
    "        if training_stall_min == 9999999.0 or training_stall_max < training_stall_new_val:\n",
    "            training_stall_min = training_stall_new_val\n",
    "\n",
    "    delay_time = training_stall_max - training_stall_min\n",
    "    done_row[\"Delay time (sec)\"] = delay_time\n",
    "    \n",
    "    done_row[\"Training stall time (sec)\"] = training_stall_max\n",
    "    \n",
    "    return done_row\n",
    "\n",
    "@ray.remote\n",
    "def simulation(FETCH_ALIGN,START_ALIGN, conf, trainType, simulation_df, max_index_number):\n",
    "    simulated_df = pd.DataFrame(columns=columns)\n",
    "    done_df = pd.DataFrame(columns=[\"Slowest end time\", \"Training end time\", \"Delay time (sec)\",\"Training stall time (sec)\"]+gpu_training_stall_col)\n",
    "    \n",
    "    for idx, row in simulation_df.iterrows():\n",
    "        simulated_row = {}\n",
    "        simulated_row[train_col[0]] = row[train_col[0]]\n",
    "        simulated_row[train_col[1]] = row[train_col[1]]\n",
    "        \n",
    "        simulated_row.update(simulate_dataload(FETCH_ALIGN, START_ALIGN, idx, row, simulated_df, done_df))\n",
    "\n",
    "        simulated_df.loc[len(simulated_df)] = simulated_row\n",
    "#         print(done_row)\n",
    "        done_df.loc[len(simulated_df)] = simulate_training(idx, simulated_df, done_df)\n",
    "#     print(done_df)   \n",
    "    sim_train_df = pd.DataFrame()\n",
    "    iterTime = done_df[\"Training end time\"][1:].reset_index(drop = True) - done_df[\"Training end time\"][:max_index_number].reset_index(drop = True)\n",
    "    iterTime = iterTime / np.timedelta64(1, 's')\n",
    "    out = simulated_df.loc[0][gpu_fetch_col].max()+ conf[\"TRAINING_TIME\"]\n",
    "    first = pd.Series(out)\n",
    "    iterTime= pd.concat([first,iterTime]).reset_index(drop=True)\n",
    "    sim_train_df[train_col] = simulated_df[train_col]\n",
    "    sim_train_df[\"Iteration time (sec)\"] = iterTime\n",
    "    sim_train_df[gpu_training_stall_col] = done_df[gpu_training_stall_col].reset_index(drop=True)\n",
    "    sim_train_df[\"Training stall time (sec)\"] = done_df[\"Training stall time (sec)\"].reset_index(drop=True)\n",
    "    sim_train_df[\"Delay time (sec)\"] = done_df[\"Delay time (sec)\"].reset_index(drop=True)\n",
    "    sim_train_df[\"Batch fetch time diff (sec)\"]  = (simulated_df[gpu_fetch_done_col].max(axis=1) - simulated_df[gpu_fetch_done_col].min(axis=1)).dt.total_seconds()\n",
    "    sim_train_df[\"Batch fetch start time diff (sec)\"] = (simulated_df[gpu_start_col].max(axis=1) - simulated_df[gpu_start_col].min(axis=1)).dt.total_seconds()\n",
    "    \n",
    "    os.makedirs(f\"./{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/debug\", exist_ok=True)\n",
    "    \n",
    "    sim_train_df.to_csv(f\"./{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/{origin_filename}.csv\")\n",
    "    \n",
    "    # For debugging\n",
    "    sanity_check_df = done_df[done_df[\"Slowest end time\"] > done_df[\"Training end time\"]]\n",
    "    if not sanity_check_df.empty:\n",
    "        print(f\"Error in this FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}\")\n",
    "        print(done_df[done_df[\"Slowest end time\"] > done_df[\"Training end time\"]])\n",
    "    simulated_df.to_csv(f\"./{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/debug/dataload_sim.csv\")\n",
    "    done_df.to_csv(f\"./{trainType}/FETCH_ALIGN_{FETCH_ALIGN}_START_ALIGN_{START_ALIGN}/debug/train_sim.csv\")\n",
    "    return simulated_df\n",
    "\n",
    "# Initialization\n",
    "conf_combinations = list(itertools.product(FETCH_ALIGNs, START_ALIGNs))\n",
    "result_ids = []\n",
    "for FETCH_ALIGN, START_ALIGN in conf_combinations:\n",
    "    result_ids.append(simulation.remote(FETCH_ALIGN,START_ALIGN, conf_share, \n",
    "                                        trainType_share, simulation_df_share, max_index_number_share))\n",
    "    \n",
    "while len(result_ids):\n",
    "    done_id, result_ids = ray.wait(result_ids)\n",
    "    ray.get(done_id)\n",
    "#     # Debug break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a458d-62d8-4c52-afd3-ea95169ae55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-27 13:36:10,239\tERROR worker.py:78 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::simulation()\u001b[39m (pid=64124, ip=10.20.22.156)\n",
      "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n",
      "    return function(*args, **kwargs)\n",
      "  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n",
      "    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n",
      "    indexer = self.slice_indexer(start, stop, step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n",
      "    end_slice = self.get_slice_bound(end, \"right\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n",
      "    raise self._invalid_indexer(\"slice\", label)\n",
      "TypeError: cannot do slice indexing on Index with these indexers [nan] of type float\n",
      "2021-08-27 13:36:10,240\tERROR worker.py:78 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::simulation()\u001b[39m (pid=64125, ip=10.20.22.156)\n",
      "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n",
      "    return function(*args, **kwargs)\n",
      "  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n",
      "    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n",
      "    indexer = self.slice_indexer(start, stop, step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n",
      "    end_slice = self.get_slice_bound(end, \"right\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n",
      "    raise self._invalid_indexer(\"slice\", label)\n",
      "TypeError: cannot do slice indexing on Index with these indexers [nan] of type float\n",
      "2021-08-27 13:36:10,241\tERROR worker.py:78 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::simulation()\u001b[39m (pid=64119, ip=10.20.22.156)\n",
      "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n",
      "    return function(*args, **kwargs)\n",
      "  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n",
      "    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n",
      "    indexer = self.slice_indexer(start, stop, step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n",
      "    end_slice = self.get_slice_bound(end, \"right\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n",
      "    raise self._invalid_indexer(\"slice\", label)\n",
      "TypeError: cannot do slice indexing on Index with these indexers [nan] of type float\n",
      "2021-08-27 13:36:10,241\tERROR worker.py:78 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::simulation()\u001b[39m (pid=64118, ip=10.20.22.156)\n",
      "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n",
      "    return function(*args, **kwargs)\n",
      "  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n",
      "    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n",
      "    indexer = self.slice_indexer(start, stop, step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n",
      "    end_slice = self.get_slice_bound(end, \"right\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n",
      "    raise self._invalid_indexer(\"slice\", label)\n",
      "TypeError: cannot do slice indexing on Index with these indexers [nan] of type float\n",
      "2021-08-27 13:36:10,242\tERROR worker.py:78 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::simulation()\u001b[39m (pid=64123, ip=10.20.22.156)\n",
      "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n",
      "    return function(*args, **kwargs)\n",
      "  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n",
      "    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n",
      "    indexer = self.slice_indexer(start, stop, step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n",
      "    end_slice = self.get_slice_bound(end, \"right\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n",
      "    raise self._invalid_indexer(\"slice\", label)\n",
      "TypeError: cannot do slice indexing on Index with these indexers [nan] of type float\n",
      "2021-08-27 13:36:10,242\tERROR worker.py:78 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::simulation()\u001b[39m (pid=64122, ip=10.20.22.156)\n",
      "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n",
      "    return function(*args, **kwargs)\n",
      "  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n",
      "    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n",
      "    indexer = self.slice_indexer(start, stop, step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n",
      "    end_slice = self.get_slice_bound(end, \"right\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n",
      "    raise self._invalid_indexer(\"slice\", label)\n",
      "TypeError: cannot do slice indexing on Index with these indexers [nan] of type float\n",
      "2021-08-27 13:36:10,243\tERROR worker.py:78 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::simulation()\u001b[39m (pid=64121, ip=10.20.22.156)\n",
      "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n",
      "    return function(*args, **kwargs)\n",
      "  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n",
      "    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n",
      "    indexer = self.slice_indexer(start, stop, step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n",
      "    end_slice = self.get_slice_bound(end, \"right\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n",
      "    raise self._invalid_indexer(\"slice\", label)\n",
      "TypeError: cannot do slice indexing on Index with these indexers [nan] of type float\n",
      "2021-08-27 13:36:10,243\tERROR worker.py:78 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::simulation()\u001b[39m (pid=64120, ip=10.20.22.156)\n",
      "  File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 330, in _function_with_tracing\n",
      "    return function(*args, **kwargs)\n",
      "  File \"<ipython-input-4-9b1befbba0b7>\", line 107, in simulation\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 966, in __getitem__\n",
      "    return self._get_with(key)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/series.py\", line 973, in _get_with\n",
      "    slobj = self.index._convert_slice_indexer(key, kind=\"getitem\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3753, in _convert_slice_indexer\n",
      "    indexer = self.slice_indexer(start, stop, step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5686, in slice_indexer\n",
      "    start_slice, end_slice = self.slice_locs(start, end, step=step)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5894, in slice_locs\n",
      "    end_slice = self.get_slice_bound(end, \"right\")\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5798, in get_slice_bound\n",
      "    label = self._maybe_cast_slice_bound(label, side)\n",
      "  File \"/home/chanho/anaconda3/envs/torchtest/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5750, in _maybe_cast_slice_bound\n",
      "    raise self._invalid_indexer(\"slice\", label)\n",
      "TypeError: cannot do slice indexing on Index with these indexers [nan] of type float\n",
      "2021-08-27 13:39:49,171\tERROR worker.py:1191 -- listen_error_messages_raylet: Connection closed by server.\n",
      "2021-08-27 13:39:49,175\tERROR worker.py:468 -- print_logs: Connection closed by server.\n",
      "2021-08-27 13:39:49,175\tERROR import_thread.py:88 -- ImportThread: Connection closed by server.\n"
     ]
    }
   ],
   "source": [
    "dir_names = glob.glob(\n",
    "               f\"./{trainType}/*/*.csv\")\n",
    "\n",
    "dataset_col_name = [\"Align\",\"Log type\", \"Dataset size(GB)\", \"Model\", \"Augmentation\", \"Worker\", \"Worker batch size\", \"Epoch\", \"Batch size\", \"Avg iteration time (sec)\",\n",
    "                                \"Avg throughput (images/sec)\", \"Avg training stall time (sec)\", \"Avg delay time (sec)\", \"Avg preprocessing start diff (sec)\", \"Avg preprocessing diff (sec)\"]\n",
    "total_log = [] \n",
    "\n",
    "for logdir in dir_names:\n",
    "    split_logdir = logdir.split('/')\n",
    "    align_type = split_logdir[-2]\n",
    "    parse_filename = split_logdir[-1]\n",
    "    logdir_list = parse_filename.split(\"_\")\n",
    "#         print(logdir_list)\n",
    "    logtype = logdir_list[0]\n",
    "    dataset = logdir_list[1]\n",
    "    aug = find_value(logdir_list, dataset)\n",
    "    model = find_value(logdir_list, aug)\n",
    "    epoch = find_value(logdir_list, model)\n",
    "    batchsize = find_value(logdir_list, epoch)\n",
    "    worker = find_value(logdir_list, batchsize)\n",
    "    thread = find_value(logdir_list, worker).replace(\".csv\",\"\")\n",
    "    model = model.replace(\"_\", \"\")\n",
    "\n",
    "    epoch_num = int(epoch.replace(\"epoch\", \"\"))\n",
    "    batchsize_num = int(batchsize.replace(\"b\", \"\"))\n",
    "    single_batchsize_num = batchsize_num/gpu_num\n",
    "    conf[\"WORKER_NUM\"] = int(worker.replace(\"worker\", \"\"))\n",
    "    thread_num = int(thread.replace(\"thread\", \"\"))\n",
    "\n",
    "    df = pd.read_csv(logdir, index_col=None)\n",
    "    df = df[df[\"Index number\"]>10]\n",
    "#     gpu_log = []\n",
    "\n",
    "#     for i in range(gpu_num):\n",
    "#         gpu_df = df[df[\"GPU\"] == i].dropna()\n",
    "#         gpu_epoch_time = f'{round(gpu_df[\"Iteration time (sec)\"].mean(),4)}±{round(gpu_df[\"Iteration time (sec)\"].std(),4)}'\n",
    "#         gpu_log.append(gpu_epoch_time)\n",
    "#         gpu_stall_time = f'{round(gpu_df[\"Training stall time (sec)\"].mean(),4)}±{round(gpu_df[\"Training stall time (sec)\"].std(),4)}'\n",
    "#         gpu_log.append(gpu_stall_time)\n",
    "\n",
    "\n",
    "#     df = df[df[\"Step\"] > 10]\n",
    "#     filtered_avg_epoch_time = round(\n",
    "#         df[\"Iteration time (sec)\"].astype(float).sum()/(int(epoch_num)-1), 2)\n",
    "#     print(df.describe())\n",
    "#     print(\"\\n\")\n",
    "    # print(parse_filename, df[\"Iteration time (sec)\"])\n",
    "    iter_origin = df[\"Iteration time (sec)\"].mean()\n",
    "    iter_avg = f'{round(iter_origin,4)}±{round(df[\"Iteration time (sec)\"].std(),4)}'\n",
    "    data_avg = f'{round(df[\"Training stall time (sec)\"].mean(),4)}±{round(df[\"Training stall time (sec)\"].std(),4)}'\n",
    "    delay_avg = f'{round(df[\"Delay time (sec)\"].mean(),4)}±{round(df[\"Delay time (sec)\"].std(),4)}'\n",
    "    fetch_avg = f'{round(df[\"Batch fetch time diff (sec)\"].mean(),4)}±{round(df[\"Batch fetch time diff (sec)\"].std(),4)}'\n",
    "    fetch_start_avg = f'{round(df[\"Batch fetch start time diff (sec)\"].mean(),4)}±{round(df[\"Batch fetch start time diff (sec)\"].std(),4)}'\n",
    "\n",
    "    throughput_origin = single_batchsize_num/iter_origin\n",
    "    throughput_avg = round(throughput_origin, 4)\n",
    "    # # [Note] :\n",
    "    # # Deprecated throughput avg,\n",
    "    # # theoretically wrong in mathematic, Please check below link\n",
    "    # # https://fxloader.com/inverse_of_an_average_compared_to_averages_of_inverses/\n",
    "    # throughput_avg = f'{round(df[\"Throughput (image/sec)\"].mean(),2)}±{round(df[\"Throughput (image/sec)\"].std(),4)}'\n",
    "\n",
    "    # FIXME: Hard coded as imagenet avg size (MB)\n",
    "    processed_data_avg = throughput_origin * 105.53 / 1024\n",
    "\n",
    "    total_loglet = [align_type, logtype, dataset, model, aug, conf[\"WORKER_NUM\"], thread_num, epoch_num, batchsize_num,\n",
    "                    iter_avg, throughput_avg, data_avg, delay_avg, fetch_start_avg, fetch_avg]\n",
    "#     total_loglet.extend(gpu_log)\n",
    "    total_log.append(total_loglet)\n",
    "\n",
    "avg_df = pd.DataFrame(total_log,\n",
    "                      columns=dataset_col_name)\n",
    "avg_df.dropna().to_csv(f\"./{trainType}/total_summary.csv\",\n",
    "                       sep=',', na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b2bbb-ad50-4019-b9d2-eb32de7ffa90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
