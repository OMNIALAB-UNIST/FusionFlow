{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T10:24:09.491289Z",
     "start_time": "2021-06-14T10:24:09.056716Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 19:27:17.434 DEBUG:\tStart Process0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before decoding img size: get_size of 108063 bytes\n",
      "after decoding img size: get_size of 562533 bytes\n",
      "no crop resize sample size: get_size of 2250000 bytes\n",
      "no crop resize sample element size: 4, sample nelement: 562500\n",
      "Type: torch.float32, torch.Size([3, 375, 500])\n",
      "resized and crop size: get_size of 150561 bytes\n",
      "sample size: get_size of 602112 bytes\n",
      "sample element size: 4, sample nelement: 150528\n",
      "Type: torch.float32, torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 19:27:17.488 DEBUG:\tEnd Process0 Access time: 0.031310392543673515\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Manager, Barrier\n",
    "import time, logging, os, copy, pathlib, io, sys\n",
    "import statistics as stats\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s.%(msecs)03d %(levelname)s:\\t%(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "log = logging.getLogger(__name__)\n",
    "from shared_memory_dict import SharedMemoryDict\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "\n",
    "num_p = 1\n",
    "rep = 1\n",
    "BATCHSIZE=1\n",
    "synthetic = False\n",
    "decoding = True\n",
    "dir_path = '/home/chanho/ssd2/1024batch/train'\n",
    "\n",
    "augmentations=[\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "#             transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(p=1.0),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]\n",
    "\n",
    "resizeAndCrop=[\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224)\n",
    "]\n",
    "\n",
    "toTensor=[\n",
    "    transforms.ToTensor(),\n",
    "]\n",
    "\n",
    "augmentations_composed=transforms.Compose(augmentations)\n",
    "augmentations_composed2=transforms.Compose(resizeAndCrop)\n",
    "augmentations_composed3=transforms.Compose(toTensor)\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "    \n",
    "def memloader(byte_data):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    img = Image.open(byte_data)\n",
    "    return img.convert('RGB')\n",
    "    \n",
    "def aug(imgd,result,barrier,num,preloading,num_p,rep):\n",
    "    import psutil\n",
    "    p = psutil.Process()\n",
    "    p.cpu_affinity([num])\n",
    "    \n",
    "    for j in range(rep):\n",
    "        arr = []\n",
    "        \n",
    "        barrier.wait()\n",
    "        log.debug(f\"Start Process{num}\")\n",
    "        start=time.perf_counter()\n",
    "    \n",
    "        for i in range(BATCHSIZE):\n",
    "            if preloading:\n",
    "                print(f\"before decoding img size: get_size of {imgd[num+num_p*i].getbuffer().nbytes} bytes\")\n",
    "                img = memloader(imgd[num+num_p*i])\n",
    "                print(f\"after decoding img size: get_size of {sys.getsizeof(img.tobytes())} bytes\")\n",
    "            else:\n",
    "                img = imgd[num+num_p*i]\n",
    "                \n",
    "            sample3 = augmentations_composed3(img)\n",
    "            print(f\"no crop resize sample size: get_size of {sample3.element_size() * sample3.nelement()} bytes\")\n",
    "            print(f\"no crop resize sample element size: {sample3.element_size()}, sample nelement: {sample3.nelement()}\")\n",
    "            print(f\"Type: {sample3.dtype}, {sample3.shape}\")\n",
    "            sample = augmentations_composed(img)\n",
    "            sample2 = augmentations_composed2(img)\n",
    "            print(f\"resized and crop size: get_size of {sys.getsizeof(sample2.tobytes())} bytes\")\n",
    "            \n",
    "            \n",
    "            print(f\"sample size: get_size of {sample.element_size() * sample.nelement()} bytes\")\n",
    "            print(f\"sample element size: {sample.element_size()}, sample nelement: {sample.nelement()}\")\n",
    "            print(f\"Type: {sample.dtype}, {sample.shape}\")\n",
    "#             arr.append(sample)\n",
    "        end=time.perf_counter()                            \n",
    "    \n",
    "        elapsed_time=end-start\n",
    "        log.debug(f\"End Process{num} Access time: {elapsed_time}\")\n",
    "        result.append(elapsed_time)\n",
    "        \n",
    "    return arr\n",
    "\n",
    "\n",
    "manager1 = Manager()\n",
    "manager2 = Manager()\n",
    "manager3 = Manager()\n",
    "manager4 = Manager()\n",
    "\n",
    "# d = [{},{},{},{}]\n",
    "# d = [manager1.dict(),manager1.dict(),manager1.dict(),manager1.dict()]\n",
    "# d = [manager1.dict(),manager2.dict(),manager3.dict(),manager4.dict()]\n",
    "d = [manager1.dict(),manager2.dict(),manager3.dict(),manager4.dict()]\n",
    "results = [manager1.list(),manager2.list(),manager3.list(),manager4.list()]\n",
    "\n",
    "dataset_size = 30 # MB\n",
    "size = dataset_size * 1024 * 1024\n",
    "\n",
    "for i in range(num_p*256):\n",
    "    if synthetic:\n",
    "        d[i % num_p][i] = torch.rand((3, 224, 224))\n",
    "    elif decoding:\n",
    "        path =pathlib.Path(f'/home/chanho/ssd2/1024batch/train/n02364673/{i}.JPEG')\n",
    "#         print(f\"path size: {os.stat(path).st_size}\")\n",
    "        with open(path, 'rb') as f:\n",
    "            img_byte = f.read()\n",
    "            img_byte_mem = io.BytesIO(img_byte)\n",
    "#         print(f\"img_byte_mem size: get_size of {sys.getsizeof(img_byte_mem.tell())} bytes\")\n",
    "        d[i % num_p][i] = img_byte_mem\n",
    "    else:\n",
    "        path =pathlib.Path(f'/home/chanho/ssd2/1024batch/train/n02364673/{i}.JPEG')\n",
    "        d[i % num_p][i] = pil_loader(path)\n",
    "#         print(f\"img_byte_mem size: get_size of {sys.getsizeof(d[i % num_p][i].tell())} bytes\")\n",
    "        \n",
    "        \n",
    "    \n",
    "#         smd[i % 4][i] = f\"test{i}\"\n",
    "barrier=Barrier(num_p)\n",
    "ps = []\n",
    "for i in range(num_p):\n",
    "#         p = Process(target=shdf, args=(smd[i % 4],barrier,i))\n",
    "    p=Process(target=aug, args=(d[i % num_p],results[i % num_p],barrier,i,decoding, num_p, rep))\n",
    "    ps.append(p)\n",
    "\n",
    "\n",
    "for p in ps:\n",
    "    p.start()\n",
    "\n",
    "for p in ps:\n",
    "    p.join()\n",
    "    \n",
    "# for single_d in d:\n",
    "#     print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T02:24:15.739905Z",
     "start_time": "2021-06-11T02:24:15.642328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process0\n",
      "mean:  0.031310392543673515\n",
      "median:  0.031310392543673515\n"
     ]
    },
    {
     "ename": "StatisticsError",
     "evalue": "variance requires at least two data points",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a8737ce11621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_p\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nProcess{i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a8737ce11621>\u001b[0m in \u001b[0;36mstat\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"median: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"std: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     print(\"10large: \",data.nlargest(10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print(\"10small: \",data.nsmallest(10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtest/lib/python3.8/statistics.py\u001b[0m in \u001b[0;36mstdev\u001b[0;34m(data, xbar)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m     \"\"\"\n\u001b[0;32m--> 799\u001b[0;31m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtest/lib/python3.8/statistics.py\u001b[0m in \u001b[0;36mvariance\u001b[0;34m(data, xbar)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variance requires at least two data points'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStatisticsError\u001b[0m: variance requires at least two data points"
     ]
    }
   ],
   "source": [
    "def stat(data):\n",
    "#     print(\"max: \", stats.fmean(data))  \n",
    "#     print(\"min: \",stats.min())  \n",
    "    print(\"mean: \",stats.fmean(data))  \n",
    "    print(\"median: \",stats.median(data))  \n",
    "    print(\"std: \",stats.stdev(data))  \n",
    "#     print(\"10large: \",data.nlargest(10))\n",
    "#     print(\"10small: \",data.nsmallest(10))\n",
    "    print(\"quantile\",stats.quantiles(data, n=6))\n",
    "    \n",
    "for i in range(num_p) :\n",
    "    print(f\"\\nProcess{i}\")\n",
    "    stat(results[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T01:57:46.717788Z",
     "start_time": "2021-06-11T01:57:45.346Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import features\n",
    "features.check_feature(\"libjpeg_turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T01:57:46.718519Z",
     "start_time": "2021-06-11T01:57:45.349Z"
    }
   },
   "outputs": [],
   "source": [
    "# from multiprocessing import Process, Manager, Barrier\n",
    "# import time, logging, os, copy, pathlib\n",
    "# from PIL import Image\n",
    "# import torchvision.transforms as transforms\n",
    "# logging.basicConfig(level=logging.DEBUG, format='%(asctime)s.%(msecs)03d %(levelname)s:\\t%(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "# log = logging.getLogger(__name__)\n",
    "# from shared_memory_dict import SharedMemoryDict\n",
    "\n",
    "# def pil_loader(path):\n",
    "#     # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "#     with open(path, 'rb') as f:\n",
    "#         img = Image.open(f)\n",
    "#         return img.convert('RGB')\n",
    "\n",
    "# def f(d,barrier,num):\n",
    "#     barrier.wait()\n",
    "#     log.debug(f\"Start Process{num}\")\n",
    "#     start=time.perf_counter()\n",
    "#     for i in range(256):\n",
    "#         item=d[num+4*i]\n",
    "#     end=time.perf_counter()\n",
    "#     log.debug(f\"End Process{num} Access time: {end-start}\")\n",
    "#     return\n",
    "\n",
    "# num_p = 4\n",
    "\n",
    "# manager1 = Manager()\n",
    "# manager2 = Manager()\n",
    "# manager3 = Manager()\n",
    "# manager4 = Manager()\n",
    "\n",
    "# d = [manager1.dict(),manager2.dict(),manager3.dict(),manager4.dict()]\n",
    "# for i in range(num_p*256):\n",
    "#     path =pathlib.Path(f'/home/chanho/ssd2/1024batch/train/n02364673/{i}.JPEG')\n",
    "#     d[i % 4][i] = pil_loader(path)\n",
    "# barrier=Barrier(num_p)\n",
    "# ps = []\n",
    "# for i in range(num_p):\n",
    "#     p = Process(target=f, args=(d[i % 4],barrier,i))\n",
    "#     ps.append(p)\n",
    "\n",
    "# for p in ps:\n",
    "#     p.start()\n",
    "\n",
    "# for p in ps:\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T01:57:46.719521Z",
     "start_time": "2021-06-11T01:57:45.351Z"
    }
   },
   "outputs": [],
   "source": [
    "# def f(d,barrier,num):\n",
    "#     barrier.wait()\n",
    "#     log.debug(f\"Start Process{num}\")\n",
    "#     start=time.perf_counter()\n",
    "#     for i in range(256):\n",
    "#         item=d[num+4*i]\n",
    "#     end=time.perf_counter()\n",
    "#     log.debug(f\"End Process{num} Access time: {end-start}\")\n",
    "#     return\n",
    "\n",
    "# def pil_loader(path):\n",
    "#     # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "#     with open(path, 'rb') as f:\n",
    "#         img = Image.open(f)\n",
    "#         return img.convert('RGB')\n",
    "\n",
    "# num_p = 4\n",
    "# manager1 = Manager()\n",
    "# manage_dict=manager1.dict()\n",
    "# d = [manage_dict,manage_dict,manage_dict,manage_dict]\n",
    "# for i in range(num_p*256):\n",
    "#     path =pathlib.Path(f'/home/chanho/ssd2/1024batch/train/n02364673/{i}.JPEG')\n",
    "#     d[i % 4][i] = pil_loader(path)\n",
    "# barrier=Barrier(num_p)\n",
    "# ps = []\n",
    "# for i in range(num_p):\n",
    "#     p=Process(target=f, args=(d[i % 4],barrier,i))\n",
    "#     ps.append(p)\n",
    "\n",
    "# for p in ps:\n",
    "#     p.start()\n",
    "\n",
    "# for p in ps:\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T01:57:46.720224Z",
     "start_time": "2021-06-11T01:57:45.353Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_p = 4\n",
    "\n",
    "# d = [{},{},{},{}]\n",
    "# for i in range(num_p*256):\n",
    "#     path =pathlib.Path(f'/home/chanho/ssd2/1024batch/train/n02364673/{i}.JPEG')\n",
    "#     d[i % 4][i] = pil_loader(path)\n",
    "# barrier=Barrier(num_p)\n",
    "# ps = []\n",
    "# for i in range(num_p):\n",
    "#     p=Process(target=f, args=(d[i % 4],barrier,i))\n",
    "#     ps.append(p)\n",
    "\n",
    "# for p in ps:\n",
    "#     p.start()\n",
    "\n",
    "# for p in ps:\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T01:57:46.721200Z",
     "start_time": "2021-06-11T01:57:45.355Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
