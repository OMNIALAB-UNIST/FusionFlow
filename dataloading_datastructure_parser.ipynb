{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'training_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-23845c94a1e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'training_info'"
     ]
    }
   ],
   "source": [
    "import os, glob, shutil, argparse, re, copy\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import training_info\n",
    "\n",
    "logdir=training_info.logdir\n",
    "dir_pattern = logdir+'/{}/{}/{}/{}/epoch{}/b{}/worker{}/thread{}/'\n",
    "aug_pattern = logdir+'/{}/{}/'\n",
    "simple_dir_pattern = logdir+'/{}'\n",
    "logtypes=training_info.logtypes\n",
    "datasets=training_info.datasets\n",
    "models=training_info.models\n",
    "term=training_info.term\n",
    "output_file=\"output.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_only': ['./log/DDP/train_only/1024batch10/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/train_only/1024batch/default/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/train_only/1024batch/default/resnet18/epoch5/b1024/worker24/thread0/', './log/DDP/train_only/1024batch/default/resnet18/epoch5/b256/worker24/thread0/'], 'loadNtrain': ['./log/DDP/loadNtrain/size5/default/resnet18/epoch5/b256/worker2/thread0/', './log/DDP/loadNtrain/1024batch10/default/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/loadNtrain/1024batch10/default/resnet18/epoch5/b1024/worker24/thread0/', './log/DDP/loadNtrain/1024batch10/default/resnet18/epoch5/b256/worker24/thread0/', './log/DDP/loadNtrain/1024batch/default/resnet18/epoch5/b1024/worker2/thread0/'], 'prepNloadNtrain': ['./log/DDP/prepNloadNtrain/size5/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size5/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrain/size5/default/resnet18/epoch5/b1024/worker8/thread0/', './log/DDP/prepNloadNtrain/size5/augmix/resnet18/epoch5/b1024/worker1/thread0/', './log/DDP/prepNloadNtrain/size5/augmix/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size5/augmix/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size5/randaugment/resnet18/epoch5/b1024/worker1/thread0/', './log/DDP/prepNloadNtrain/size5/randaugment/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size5/randaugment/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size2/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size2/augmix/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size2/randaugment/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size3/default/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size3/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size3/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrain/size3/default/resnet18/epoch5/b1024/worker8/thread0/', './log/DDP/prepNloadNtrain/size3/augmix/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size3/augmix/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size3/randaugment/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size3/randaugment/resnet18/epoch5/b1024/worker4/thread0/'], 'fsNprepNloadNtrain': ['./log/DDP/fsNprepNloadNtrain/size5/default/resnet18/epoch5/b1024/worker2/thread0/'], 'fetchNfsNprepNloadNtrain': [], 'prepNloadNtrainCustom': ['./log/DDP/prepNloadNtrainCustom/size3/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrainCustom/size3/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrainCustom/size3/default/resnet18/epoch5/b1024/worker8/thread0/'], 'prepNloadNtrainNoPin': [], 'prepNloadNtrainSyncStart': ['./log/DDP/prepNloadNtrainSyncStart/size3/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrainSyncStart/size3/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrainSyncStart/size3/default/resnet18/epoch5/b1024/worker8/thread0/']}\n"
     ]
    }
   ],
   "source": [
    "def get_dirname():\n",
    "    dir_names = {}\n",
    "    for logtype in logtypes:\n",
    "        dir_names[logtype]=glob.glob(simple_dir_pattern.format(logtype)+f\"/*/*/*/*/*/*/*/\")\n",
    "\n",
    "    return dir_names\n",
    "\n",
    "def replace_str(target):\n",
    "    target=target.replace('\\n', '')\n",
    "    target=target.replace(',', '')\n",
    "    return target\n",
    "\n",
    "def find_value(arr, target, jumpto=1):\n",
    "    try:\n",
    "        num=replace_str(arr[arr.index(target)+jumpto])\n",
    "    except:\n",
    "        print(arr, target, arr[arr.index(target)+jumpto])\n",
    "        num='NA'\n",
    "    return num\n",
    "\n",
    "parsed_dir=training_info.parsed_dir + \"/ds\"\n",
    "os.makedirs(parsed_dir, exist_ok=True)\n",
    "\n",
    "breakdown_col_name=[\"Time\",\"Index queues\",\"Worker result queue\",\"Data queue\",\"Consumed\"]\n",
    "\n",
    "dir_names=get_dirname()\n",
    "print(dir_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parser(dir_names, datasets):\n",
    "    index_queue_put_pattern = re.compile(\"PUT .* worker_queue_idx\")\n",
    "    index_queue_get_pattern = re.compile(\"worker_id: [0-9]+, GET\")\n",
    "    worker_result_queue_put_pattern = re.compile(\"worker_id: [0-9]+, PUT\")\n",
    "    worker_result_queue_get_pattern = re.compile(\"pin_memory GET .* _worker_result_queue\")\n",
    "    data_queue_put_pattern = re.compile(\"pin_memory PUT .* data_queue\")\n",
    "    data_queue_get_pattern = re.compile(\"GET data object at .* _data_queue\")\n",
    "    consumption_pattern = re.compile(\"Finish iteration[0-9]+\")\n",
    "    \n",
    "    for logtype in logtypes:\n",
    "        for logdir in dir_names[logtype]:\n",
    "            if not os.path.exists(logdir):\n",
    "                    continue\n",
    "            logdir_list=logdir.split('/')\n",
    "            \n",
    "            dataset=find_value(logdir_list, logtype)\n",
    "            aug=find_value(logdir_list, dataset)\n",
    "            model=find_value(logdir_list, aug)\n",
    "            epoch=find_value(logdir_list, model)\n",
    "            batchsize=find_value(logdir_list, epoch)\n",
    "            worker=find_value(logdir_list, batchsize)\n",
    "            \n",
    "            worker_num = int(worker.replace(\"worker\",\"\"))\n",
    "            parse_filename=f\"{logtype}_{dataset}_{model}_{aug}_{worker}_{epoch}_{batchsize}_ds\"\n",
    "            \n",
    "            logfile=logdir +\"/\"+ output_file\n",
    "            breakdown_parsed_log = []\n",
    "            weird_idx_log=[]\n",
    "            weird_idx_info=[0]\n",
    "            data_log=[0,0,0,0,0]\n",
    "            worker_name = []\n",
    "            weird_idx_name=[\"Time\"]\n",
    "            \n",
    "            for i in range(worker_num):\n",
    "                data_log.append(0)\n",
    "                worker_name.append(f\"Worker{i} index queue\")\n",
    "            \n",
    "            for line in open(logfile, 'r').readlines():\n",
    "                if re.search(index_queue_put_pattern, line) is not None: # start log\n",
    "                    replace_txt=line.replace('\\t',' ')\n",
    "                    test =replace_txt.split(' ')\n",
    "                    info = list(filter(lambda x: x != \"\", test))\n",
    "                    \n",
    "                    data_log[0] = find_value(info, \"DEBUG:\", -1) # Time\n",
    "                    data_log[1] += 1\n",
    "                    worker_queue = find_value(info, \"_index_queues:\\n\", -1)\n",
    "                    worker_queue_num = int(worker_queue.replace(\"worker_queue_idx\",\"\"))\n",
    "                    data_log[5+worker_queue_num] += 1\n",
    "                    \n",
    "                    breakdown_parsed_log.append(data_log)\n",
    "                    data_log=copy.deepcopy(data_log)\n",
    "                                        \n",
    "                    not_processed_batch_num = find_value(info, \"PUT\")\n",
    "                    not_processed_batch_num=not_processed_batch_num.replace(\"(\",\"\")\n",
    "                    batch_num=int(not_processed_batch_num.replace(\",\",\"\"))\n",
    "                    if batch_num >= len(weird_idx_info)-1:\n",
    "                        weird_idx_name.append(f\"Batch Idx {batch_num}\")\n",
    "                        weird_idx_info.append(0)\n",
    "                    \n",
    "                elif re.search(index_queue_get_pattern, line) is not None: # start log\n",
    "                    replace_txt=line.replace('\\t',' ')\n",
    "                    test =replace_txt.split(' ')\n",
    "                    info = list(filter(lambda x: x != \"\", test))\n",
    "                                        \n",
    "                    data_log[0] = find_value(info, \"DEBUG:\", -1) # Time\n",
    "                    data_log[1] -= 1\n",
    "                    worker_queue = find_value(info, \"worker_id:\")\n",
    "                    worker_queue_num = int(worker_queue.replace(\",\",\"\"))\n",
    "                    data_log[5+worker_queue_num] -= 1\n",
    "                    \n",
    "                    breakdown_parsed_log.append(data_log)\n",
    "                    data_log=copy.deepcopy(data_log)\n",
    "                elif re.search(worker_result_queue_put_pattern, line) is not None: # start log\n",
    "                    replace_txt=line.replace('\\t',' ')\n",
    "                    test =replace_txt.split(' ')\n",
    "                    info = list(filter(lambda x: x != \"\", test))\n",
    "                    \n",
    "                    data_log[0] = find_value(info, \"DEBUG:\", -1) # Time\n",
    "                    data_log[2] += 1\n",
    "\n",
    "                    breakdown_parsed_log.append(data_log)\n",
    "                    data_log=copy.deepcopy(data_log)\n",
    "                elif re.search(worker_result_queue_get_pattern, line) is not None: # start log\n",
    "                    replace_txt=line.replace('\\t',' ')\n",
    "                    test =replace_txt.split(' ')\n",
    "                    info = list(filter(lambda x: x != \"\", test))\n",
    "                    \n",
    "                    data_log[0] = find_value(info, \"DEBUG:\", -1) # Time\n",
    "                    data_log[2] -= 1\n",
    "\n",
    "                    breakdown_parsed_log.append(data_log)\n",
    "                    data_log=copy.deepcopy(data_log)\n",
    "                    \n",
    "                elif re.search(data_queue_put_pattern, line) is not None: # start log\n",
    "                    replace_txt=line.replace('\\t',' ')\n",
    "                    test =replace_txt.split(' ')\n",
    "                    info = list(filter(lambda x: x != \"\", test))\n",
    "                    \n",
    "                    data_log[0] = find_value(info, \"DEBUG:\", -1) # Time\n",
    "                    weird_idx_info[0] = data_log[0]\n",
    "                    data_log[3] += 1\n",
    "\n",
    "                    breakdown_parsed_log.append(data_log)\n",
    "                    data_log=copy.deepcopy(data_log)\n",
    "                    \n",
    "                    not_processed_batch_num = find_value(info, \"PUT\")\n",
    "                    not_processed_batch_num=not_processed_batch_num.replace(\"(\",\"\")\n",
    "                    batch_num=int(not_processed_batch_num.replace(\",\",\"\"))\n",
    "                    try:\n",
    "                        weird_idx_info[1+batch_num]+=1\n",
    "                    except:\n",
    "                        print(batch_num)\n",
    "                        print(weird_idx_info)\n",
    "                        print(weird_idx_log)\n",
    "                        return\n",
    "                    \n",
    "                    weird_idx_log.append(weird_idx_info)\n",
    "                    weird_idx_info=copy.deepcopy(weird_idx_info)\n",
    "                elif re.search(data_queue_get_pattern, line) is not None: # start log\n",
    "                    replace_txt=line.replace('\\t',' ')\n",
    "                    test =replace_txt.split(' ')\n",
    "                    info = list(filter(lambda x: x != \"\", test))\n",
    "                    \n",
    "                    data_log[0] = find_value(info, \"DEBUG:\", -1) # Time\n",
    "                    data_log[3] -= 1\n",
    "\n",
    "                    breakdown_parsed_log.append(data_log)\n",
    "                    data_log=copy.deepcopy(data_log)\n",
    "                elif re.search(consumption_pattern, line): # start log\n",
    "                    replace_txt=line.replace('\\t',' ')\n",
    "                    test =replace_txt.split(' ')\n",
    "                    info = list(filter(lambda x: x != \"\", test))\n",
    "                    \n",
    "                    data_log[0] = find_value(info, \"DEBUG:\", -1) # Time\n",
    "                    data_log[4] += 1\n",
    "\n",
    "                    breakdown_parsed_log.append(data_log)\n",
    "                    data_log=copy.deepcopy(data_log)\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            current_col_name = breakdown_col_name +worker_name\n",
    "            breakdown_df = pd.DataFrame(breakdown_parsed_log,\n",
    "                              columns=current_col_name)\n",
    "            breakdown_df.to_csv(parsed_dir+\"/\"+parse_filename+\".csv\", sep=',', na_rep='NA')\n",
    "#             print(weird_idx_name)\n",
    "            weird_idx_df = pd.DataFrame(weird_idx_log,\n",
    "                              columns=weird_idx_name)\n",
    "            weird_idx_df.to_csv(parsed_dir+\"/\"+parse_filename+\"WeirdIdx.csv\", sep=',', na_rep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6638f17f7780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-6753459d5579>\u001b[0m in \u001b[0;36mparser\u001b[0;34m(dir_names, datasets)\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mweird_idx_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweird_idx_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mweird_idx_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweird_idx_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0;32melif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_queue_get_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# start log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0mreplace_txt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mreplace_txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    182\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser(dir_names, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
