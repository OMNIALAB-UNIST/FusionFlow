{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil, argparse, re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import training_info\n",
    "\n",
    "logdir=training_info.logdir\n",
    "dir_pattern = logdir+'/{}/{}/{}/{}/epoch{}/b{}/worker{}/thread{}/'\n",
    "aug_pattern = logdir+'/{}/{}/'\n",
    "simple_dir_pattern = logdir+'/{}'\n",
    "logtypes=training_info.logtypes\n",
    "datasets=training_info.datasets\n",
    "models=training_info.models\n",
    "term=training_info.term\n",
    "output_file=\"pid.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_only': ['./log/DDP/train_only/1024batch10/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/train_only/1024batch/default/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/train_only/1024batch/default/resnet18/epoch5/b1024/worker24/thread0/', './log/DDP/train_only/1024batch/default/resnet18/epoch5/b256/worker24/thread0/'], 'loadNtrain': ['./log/DDP/loadNtrain/size5/default/resnet18/epoch5/b256/worker2/thread0/', './log/DDP/loadNtrain/1024batch10/default/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/loadNtrain/1024batch10/default/resnet18/epoch5/b1024/worker24/thread0/', './log/DDP/loadNtrain/1024batch10/default/resnet18/epoch5/b256/worker24/thread0/', './log/DDP/loadNtrain/1024batch/default/resnet18/epoch5/b1024/worker2/thread0/'], 'prepNloadNtrain': ['./log/DDP/prepNloadNtrain/size5/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size5/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrain/size5/default/resnet18/epoch5/b1024/worker8/thread0/', './log/DDP/prepNloadNtrain/size5/augmix/resnet18/epoch5/b1024/worker1/thread0/', './log/DDP/prepNloadNtrain/size5/augmix/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size5/augmix/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size5/randaugment/resnet18/epoch5/b1024/worker1/thread0/', './log/DDP/prepNloadNtrain/size5/randaugment/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size5/randaugment/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size2/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size2/augmix/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size2/randaugment/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size3/default/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size3/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size3/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrain/size3/default/resnet18/epoch5/b1024/worker8/thread0/', './log/DDP/prepNloadNtrain/size3/augmix/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size3/augmix/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrain/size3/randaugment/resnet18/epoch5/b1024/worker2/thread0/', './log/DDP/prepNloadNtrain/size3/randaugment/resnet18/epoch5/b1024/worker4/thread0/'], 'fsNprepNloadNtrain': ['./log/DDP/fsNprepNloadNtrain/size5/default/resnet18/epoch5/b1024/worker2/thread0/'], 'fetchNfsNprepNloadNtrain': [], 'prepNloadNtrainCustom': ['./log/DDP/prepNloadNtrainCustom/size5/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrainCustom/size5/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrainCustom/size5/default/resnet18/epoch5/b1024/worker8/thread0/', './log/DDP/prepNloadNtrainCustom/size3/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrainCustom/size3/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrainCustom/size3/default/resnet18/epoch5/b1024/worker8/thread0/'], 'prepNloadNtrainNoPin': [], 'prepNloadNtrainSyncStart': ['./log/DDP/prepNloadNtrainSyncStart/size3/default/resnet18/epoch5/b1024/worker4/thread0/', './log/DDP/prepNloadNtrainSyncStart/size3/default/resnet18/epoch5/b1024/worker16/thread0/', './log/DDP/prepNloadNtrainSyncStart/size3/default/resnet18/epoch5/b1024/worker8/thread0/']}\n"
     ]
    }
   ],
   "source": [
    "def get_dirname():\n",
    "    dir_names = {}\n",
    "    for logtype in logtypes:\n",
    "        dir_names[logtype]=glob.glob(simple_dir_pattern.format(logtype)+f\"/*/*/*/*/*/*/*/\")\n",
    "\n",
    "    return dir_names\n",
    "\n",
    "def replace_str(target):\n",
    "    target=target.replace('\\n', '')\n",
    "    target=target.replace(',', '')\n",
    "    return target\n",
    "\n",
    "def find_value(arr, target, jumpto=1):\n",
    "    try:\n",
    "        num=replace_str(arr[arr.index(target)+jumpto])\n",
    "    except:\n",
    "        print(arr, target, arr[arr.index(target)+jumpto])\n",
    "        num='NA'\n",
    "    return num\n",
    "\n",
    "parsed_dir=training_info.parsed_dir+\"/cpu\"\n",
    "os.makedirs(parsed_dir, exist_ok=True)\n",
    "\n",
    "breakdown_col_name=[]\n",
    "for i in range(24):\n",
    "    breakdown_col_name.append(f\"CPU{i} Util (%)\")\n",
    "    \n",
    "breakdown_col_name.append(f\"Socket0 Util (%)\")\n",
    "breakdown_col_name.append(f\"Socket1 Util (%)\")\n",
    "breakdown_col_name.append(f\"Total CPU Util (%)\")\n",
    "dir_names=get_dirname()\n",
    "print(dir_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parser(dir_names, datasets):\n",
    "    for logtype in logtypes:\n",
    "        for logdir in dir_names[logtype]:\n",
    "            if not os.path.exists(logdir):\n",
    "                    continue\n",
    "            logdir_list=logdir.split('/')\n",
    "            \n",
    "            dataset=find_value(logdir_list, logtype)\n",
    "            aug=find_value(logdir_list, dataset)\n",
    "            model=find_value(logdir_list, aug)\n",
    "            epoch=find_value(logdir_list, model)\n",
    "            batchsize=find_value(logdir_list, epoch)\n",
    "            worker=find_value(logdir_list, batchsize)\n",
    "                             \n",
    "            parse_filename=f\"{logtype}_{dataset}_{model}_{aug}_{worker}_{epoch}_{batchsize}_cpuutil\"\n",
    "            \n",
    "            logfile=logdir +\"/\"+ output_file\n",
    "            breakdown_parsed_log = []\n",
    "            single_log = []\n",
    "            socket0_util_total=0\n",
    "            socket1_util_total=0\n",
    "            cpu_util_total=0\n",
    "            for i in range(24):\n",
    "                single_log.append(0)\n",
    "            for line in open(logfile, 'r').readlines():\n",
    "                if line.find(f'python') != -1 or line.find(f'/home/chanho/anaconda3/envs/torch1/bin') != -1: # start log\n",
    "                    replace_txt=line.replace('\\n','')\n",
    "                    replace_txt=replace_txt.replace('[','')\n",
    "                    replace_txt=replace_txt.replace(']','')\n",
    "                    test =replace_txt.split(' ')\n",
    "                    info = list(filter(lambda x: x != \"\", test))\n",
    "                    info[-1] = info[-1].replace('\\n','')\n",
    "                    info[-1] = info[-1].replace(\"/home/chanho/anaconda3/bin/\",'')\n",
    "                    info[-1] = info[-1].replace(\"/home/chanho/anaconda3/envs/torch1/bin\",'python')    \n",
    "                    info[-1] = info[-1].replace(\"/usr/bin/python3\",'python')\n",
    "                    try:\n",
    "                        cpu_util = float(find_value(info,\"python\",-7))\n",
    "                        cpu_util_total += cpu_util\n",
    "                        cpu_num = int(find_value(info,\"python\",-2))\n",
    "                        single_log[cpu_num]=cpu_util\n",
    "                    except:\n",
    "                        print(info)\n",
    "                        break\n",
    "                    if cpu_num < 12:\n",
    "                        socket0_util_total += cpu_util\n",
    "                    else:\n",
    "                        socket1_util_total += cpu_util\n",
    "                elif line.find(f'Task') != -1: # start log\n",
    "                    single_log.extend([socket0_util_total,socket1_util_total,cpu_util_total])\n",
    "                    breakdown_parsed_log.append(single_log)\n",
    "                    single_log = []\n",
    "                    for i in range(24):\n",
    "                        single_log.append(0)\n",
    "                    socket0_util_total=0\n",
    "                    socket1_util_total=0\n",
    "                    cpu_util_total = 0\n",
    "                    # append\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            breakdown_df = pd.DataFrame(breakdown_parsed_log,\n",
    "                              columns=breakdown_col_name)\n",
    "            breakdown_df.dropna().to_csv(parsed_dir+\"/\"+parse_filename+\".csv\", sep=',', na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser(dir_names, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
